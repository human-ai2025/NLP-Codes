{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1k5FyFL9xJLj",
        "YvBJJbPzUdtN"
      ],
      "mount_file_id": "1A1jta2ogAqYAcOaLLaj4YNfudXPk1aZe",
      "authorship_tag": "ABX9TyPi78IRHYPzHr+qPGogSako",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/human-ai2025/nlp_projects/blob/master/SetenceSimilarity_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Stuff"
      ],
      "metadata": {
        "id": "1k5FyFL9xJLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GTw5F4Ngt2aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0be059-300b-446c-d6f9-5727bd219c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5EhNDitxNm9",
        "outputId": "a831d6a7-d2af-40b5-8037-6d4f317f7f47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ye5Wwx_JxRas"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/tokens/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tLSwyZRoxb4R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dNyJgz5VyPVv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Dataset"
      ],
      "metadata": {
        "id": "YvBJJbPzUdtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c quora-question-pairs"
      ],
      "metadata": {
        "id": "Zq_m9jVJyciG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fafc3f-1cb7-4414-90e3-10f057004884"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading quora-question-pairs.zip to /content\n",
            " 99% 306M/309M [00:01<00:00, 217MB/s]\n",
            "100% 309M/309M [00:01<00:00, 182MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip quora-question-pairs.zip"
      ],
      "metadata": {
        "id": "4982LXL8ycen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162b7738-2e09-42e9-90b3-9d73d1bbd16a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  quora-question-pairs.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv                \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B5DGprSLzl-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23c56ca-11e5-4901-f70a-cd01832d3608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: r\n",
            "new name: test_new.csv\n",
            "  inflating: test_new.csv            \n"
          ]
        }
      ],
      "source": [
        "! unzip train.csv.zip\n",
        "! unzip test.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Stuff"
      ],
      "metadata": {
        "id": "me6Vh7kSV4Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "metadata": {
        "id": "P8tJYxhbWGgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers installation\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "insQsyQLgPuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "pl.seed_everything(41)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXLPv1GVNu3",
        "outputId": "7506fad8-e3af-4f02-d4ab-8130f73729a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_lite.utilities.seed:Global seed set to 41\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach is concat the two sentences and do sequence classification. \n",
        "- Divide the train into train, val and test\n",
        "- The test dataset will be for final testing. "
      ],
      "metadata": {
        "id": "NfC51myMYAQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.csv')\n",
        "data = data.dropna()\n",
        "print(\"The percentage of non similar question pairs is : \")\n",
        "print(len(data[data['is_duplicate']==0].index)*100/len(data.index))\n",
        "print(\"The percentage of similar question pairs is : \")\n",
        "print(len(data[data['is_duplicate']==1].index)*100/len(data.index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdBVekNGXW3c",
        "outputId": "f5f5f4d7-3b3d-4080-cad5-98d24cafd7a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of non similar question pairs is : \n",
            "63.07994073517081\n",
            "The percentage of similar question pairs is : \n",
            "36.92005926482919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarSentences(Dataset):\n",
        "    def __init__(self, tokenizer, qone, qtwo, label, maxsize):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.question1 = qone\n",
        "        self.question2 = qtwo\n",
        "        self.label = label\n",
        "        self.uniqueId = self.dataframe['id']\n",
        "        self.maxlen = maxsize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.question1) + len(self.question2) + 3\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.question1[idx]) + ' [SEP] ' + str(self.question2[idx]) \n",
        "        encodedText = self.tokenizer.encode_plus(\n",
        "            text, \n",
        "            add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
        "            max_length = self.maxlen,   # Pad & truncate all sentences.\n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,   # Construct attn. masks.\n",
        "            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "        )\n",
        "        ids = encodedText['input_ids']\n",
        "        mask = encodedText['attention_mask']\n",
        "        token_type_ids = encodedText['token_type_ids']\n",
        "\n",
        "        return {\n",
        "            'UID': self.uniqueId[idx],\n",
        "            'dataNeeded':{\n",
        "                'ids': torch.tensor(ids, dtype=torch.long), \n",
        "                'mask': torch.tensor(mask, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'labels': torch.tensor(self.label[idx], dtype=torch.float)\n",
        "            }\n",
        "            \n",
        "        }\n"
      ],
      "metadata": {
        "id": "OG3zoZW0ZTRJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceSimilarityDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, path,  batchTrainSize: 4, batchValSize: 1, maxTokenLen: 512):\n",
        "      self.path = path\n",
        "      self.trainBatch = batchTrainSize\n",
        "      self.testBatch = batchValSize\n",
        "      self.max_len = maxTokenLen\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "      \n",
        "    def setup(self, stage):\n",
        "\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.dataframe = pd.read_csv(self.path)\n",
        "            qone = list(self.dataframe['question1'].values)\n",
        "            qtwo = list(self.dataframe['question2'].values)\n",
        "            labels = list(self.dataframe['is_duplicate'].values)\n",
        "\n",
        "            # lets do stratified splitting \n",
        "            self.train_inp_q1, self.val_inp_q1, self.train_inp_q2, self.val_inp_q2, self.train_label, self.val_label  = train_test_split(qone,\n",
        "                                                                                                                                         qtwo,\n",
        "                                                                                                                                         labels,\n",
        "                                                                                                                                         random_state=2022,\n",
        "                                                                                                                                         test_size = 0.1,\n",
        "                                                                                                                                         stratify=labels)\n",
        "                                                                                    \n",
        "            self.train_inp_q1, self.test_inp_q1, self.train_inp_q2, self.test_inp_q2, self.train_label, self.test_label  = train_test_split(self.train_inp_q1,\n",
        "                                                                                                                                            self.train_inp_q2,\n",
        "                                                                                                                                            self.train_label,\n",
        "                                                                                                                                            random_state=2022,\n",
        "                                                                                                                                            test_size = 0.2,\n",
        "                                                                                                                                            stratify=self.train_label)\n",
        "            self.train_dataset = SimilarSentences(self.tokenizer, self.train_inp_q1, self.train_inp_q2, self.train_label, self.max_len)\n",
        "            self.val_dataset = SimilarSentences(self.tokenizer, self.val_inp_q1, self.val_inp_q2, self.val_label, self.max_len)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == \"test\" or stage is None:\n",
        "          self.test_dataset = SimilarSentences(self.tokenizer, self.test_inp_q1, self.test_inp_q2, self.test_label, self.max_len)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.trainBatch)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.testBatch, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.testBatch, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "AxnWWV8bhD6F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarSentenceModel(torch.nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init()\n",
        "    self.config = config\n",
        "    self.pretrainedModel = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', \n",
        "                                                                              retutn_dict = True, \n",
        "                                                                              num_labels=2\n",
        "                                                                              )\n",
        "    # the loss we use here is Binary Cross Entropy with logitics Loss \n",
        "    # its 60 40 \n",
        "    # if it doesnot work well then try weighted loss \n",
        "\n",
        "    self.loss_func = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, inputIds, attentionMask, labels=None):\n",
        "      output = self.pretrainedModel(input_ids = inputIds,attention_mask = attentionMask)\n",
        "      logits = output.logits \n",
        "      loss = 0\n",
        "      if labels:\n",
        "        loss = self.loss_func(logits.view(-1, 2), labels.view(-1, 2))\n",
        "      return loss, logits\n"
      ],
      "metadata": {
        "id": "hlha7XpspSuQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarSentenceModelPL(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        pass\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "1Ntl7Qz2smBF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}